# 개발자를 위한 레디스

## 레디스의 특징
* Remote Dictionary Server
* 레디스의 특징
  * In-Memory
  * 다양한 자료구조
  * 이벤트 루프 방식의 싱글 스레드
  * Sentinel을 통한 HA
  * 클러스터-샤드 기반의 확장성
  * 메모리는 영속적이지 않으나 AOF(Append Only File) RDB(Redis DataBase) 형식으로 디스크에 주기적으로 저장 가능
  * Message Broker

## 기본 개념
* string
  * SET
  * GET
  * INCR, INCRBY : Increment / DECR, DECRBY : Decrement
* NX, XX : 없으면 넣기, 있으면 덮어쓰기
* list : stack / queue 지원 명령어
* hash : key + item(field + value)
  * HGET, HMGET
  * HSET, HMSET
* set
* sorted set : score 값에 따라 정렬
  * 인덱스를 이용한 접근을 사용하는 경우가 있다면 List(O(n)) 보다 Sorted Set(O(log(n)))
* Geospatial
  * 경도 위도의 쌍의 집합
  * GEADD / GEOOPS
  * GEODIST : 아이템 간의 거리 조회
  * GEOSAERCH : 특정 위치 기준 거리 내 아이템 검색
    * BYRADIUS, BYBOX
* Key Managerment In Redis
  * 키가 존재하지 않을 때 삽입 > 빈 자료 구조를 자동으로 생성한 후 아이템 삽입
  * 모든 아이템 삭제 > 자동으로 키 삭제
  * 키가 없는 상태에서 읽기 전용 명령어 수행 > 아이템이 없는 것처럼 동작

## 레디스를 캐시로 쓰기
* 읽기 전략 - Look aside
  * Application <> Redis
    * IF Cache Hit
      * Use Redis Cache
    * ELSE 
      * Load Origin Database 
  * Hit Rate가 높았다면, 캐시의 장애 시 모든 커넥션이 원본 데이터베이스로 몰려 추가적인 장애가 발생할 수 있다
  * 찾고자 하는 데이터가 레디스에 없을 때만 저장하기 때문에 Lazy Loading이라고도 부른다
  * 새로운 공연 정보가 데이터베이스에만 등록된다면 캐시 미스 과정이 많이 발생한다.
  * 이때, 캐시워밍(Cache Warming) 작업을 거치는 것이 효율적일 수 있다.
* 쓰기 전략과 캐시 일관성
  * Write through
    * Database / Cache를 모두 업데이트한다.
    * 만료시간의 설정이 중요하다.
  * Cache Invalidation
    * DB Write 발생 > Cache Delete
    * 특정 데이터를 삭제하는 것이 새로운 데이터를 저장하는 것보다 리소스를 적게 사용한다.
  * Write Behind(Write Back)
    * 쓰기가 빈번하게 발생하는 서비스라면 우선 Cache에 적재하다가 > 특정 시점에 비동기적으로 Database 업데이트
  * TTL
    * 설정된 만료 시간이 지나면 레디스에서 자동으로 삭제된다.
    * 만료시간은 데이터를 조작해도 변경되지 않는다.
    * 기존 키에 새로운 값을 저장해 키를 덮어 쓸 때에는 설정한 만료시간은 사라진다.
    * 만료 키 삭제 방식
      * Passive 방식
        * 키에 접근할 때 만료 여부를 확인하고 삭제
        * 메모리는 차지하지만 실제로 접근하기 전까지는 삭제되지 않음
      * Active 방식
        * 백그라운드에서 주기적으로 만료된 키를 검사하고 삭제
        * 매 초마다 10번의 샘플링을 통해 만료된 키를 찾음
        * 샘플링된 키 중 25% 이상이 만료되었다면 다시 샘플링 진행
      * 레디스는 기본적으로 방식을 조합하여 사용
        * 메모리 효율성과 성능의 균형을 맞춤
    * 메모리 관리
      * Noeviction(기본 설정)
        * 메모리가 꽉 차면 추가 저장 시 에러 반환
        * 아주 위험한 설정
      * LRU
        * 가장 최근에 사용되지 않은 데이터부터 삭제
        * volatile-LRU
          * TTL이 있는 키만 삭제
        * allkeys-lru
          * 모든 키 삭제, 레디스 공식 문서에서는 "잘 모르겠으면, 이거 써라"
      * LFU
        * 가장 자주 사용되지 않는 데이터부터 삭제
        * LFU 옵션도 volatile, allkeys 존재
    * 캐시 스탬피드(cache stampede)
      * 캐시가 만료된 시점에 다수의 요청이 동시에 들어와
      * 모든 요청이 DB에 동시 접근하는 현상
      * "소떼가 몰려가는 것처럼" 동시에 DB에 부하가 집중됨
      * Cascading Failure
      * 적절한 만료시간 설정 / TTL이 임박한 캐시를 선계산하여 갱신하기
        * Probabilistic early recomputation(확률적 조기 재계산)
  * 세션 스토어로서의 레디스
    * Sticky Session : 특정 사용자의 요청을 항상 동일한 서버로 라우팅
    * 레디스 Hash 자료 구조로 세션을 저장하기 딱 좋다
    * 세션 스토어로서의 레디스는 데이터베이스의 서브셋이 아닌, 유일한 정보를 저장한다
## 레디스를 메시지 브로커로 쓰기
* 메시징 큐
  * 데이터 생성 > Producer
  * 데이터 소비 > Consumer
  * 소비자가 읽어갈 때 데이터를 삭제한다
  * 일대일 상황에서 사용
* 이벤트 스트림
  * 데이터 생성 > Publisher
  * 데이터 소비 > Subscriber
  * 구독자가 읽어간 데이터는 바로 삭제되지 않고 설정에 따라 특정 기간 동안 저장할 수 있다
  * 다대다 상황에서 사용
* Pub/Sub
  * 모든 데이터는 한 번 채널 전체에 전파된 뒤 삭제되는 일회성의 특징을 가지면서 잘 전달됐는지 정보를 보장하지는 않는다
  * fire-and-forget
  * Publish된 메시지는 모든 노드에 자동적으로 전달되지만, 비효율적이어서 shareded pub/sub으로 비효율을 해결한다
* Stream
  * 데이터를 계속 추가하는 방식으로 저장되는 자료 구조
  * 스트림은 컴퓨터 과학에서 연속적인 데이터의 흐름, 일정한 데이터 조각의 연속을 의미한다
  * 카프카에서의 각 스트림은 토픽이라는 이름으로 관리되지만, 레디스에서는 자료구조 자체로 관리된다
  * XADD Email * subject "first" body "hello?"
    * Email이라는 이름의 stream 자료 구조를 생성하며, subject key에 first 값을, body key에 hello? 값을 저장한다
  * 레디스 stream은 데이터를 두 가지 방식으로 읽을 수 있다
    * 실시간 리스닝
    * 특정 시점에 특정 데이터 읽어오기
  * 소비자와 소비자 그룹
    * 같은 데이터를 여러 소비자에게 전달하는 것을 팬아웃(fan-out)이라 한다
    * 레디스 stream에서는 데이터가 저장될 때마다 고유한 ID를 부여받아 순서대로 저장된다. 소비자에게 데이터가 전달될 때 그 순서는 항상 보장된다
      * 소비자 그룹 내의 한 소비자는 다른 소비자가 아직 읽지 않은 데이터만 읽는다
      * XGROUP CREATE Email EmailServiceGRoup $
        * Email Stream을 읽어가는 EmailSErviceGroup이라는 소비자 그룹을 생성하며, 현재 시점 이후의 데이터부터 리스닝하겠다
      * XREADGROUP GROUP EmailServiceGroup emailService1 COUNT 1 STREAMS Email >
        * EmailServiceGroup에 속한 emailService1 소비자가 Email stream에 있는 1개의 메시지를 읽어온다. COUNT로 소비할 메시지 개수를 직접 지정한다. >는 다른 소비자에게 전달되지 않았던 새로운 메시지를 전달하라는 것을 의미한다
      * stream과 소비자 그룹은 독립적으로 동작한다. Email stream 메시지를 읽어가기 위한 소비자 그룹은 다수 존재할 수 있으며, 소비자 그룹 1의 소비자가 A라는 메시지를 읽었다면 같은 그룹에서는 그 메시지를 다시 읽을 수 없지만, 소비자 그룹 2에서는 읽을 수 있다
    * 카프카에서 유니크 키는 파티션 내에서만 보장되기 때문에 소비자가 여러 파티션에서 토픽을 읽어갈 때에는 데이터의 순서를 보장할 수 없다
      * 데이터 순서를 보장되도록 처리하려면 소비자 그룹을 사용해야 한다
      * 카프카는 소비자 그룹에 여러 소비자를 추가할 수 있으며 소비자는 토픽 내 파티션과 일대일로 연결된다
      * 파티션 내부에서는 메시지의 순서가 보장된다
    * 카프카가 파티션이라는 개념을 이용해 소비자의 부하 분산을 관리한다면 레디스의 stream은 파티션이라는 분할 없이도 소비자 그룹이라는 개념을 이용해 여러 소비자에게 stream의 데이터를 분산시킬 수 있다는 특징을 가지고 있다
  * ACK와 보류 리스트
    * 메시지 브로커는 각 소비자에게 어떤 메시지까지 전달됐고 전달된 메시지의 처리 유무를 인지하고 있어야 한다
    * 레디스 stream은 소비자 그룹에 속한 소비자가 메시지를 읽어가면 각 소비자 별로 읽어간 메시지에 대한 리스트를 생성하며 last_delivered_id를 업데이트한다
    * 만약 서비스에 문제가 발생해 재부팅해야하는 상황에서 stream의 보류 리스트에 데이터가 남아 있는 경우 해당 데이터를 먼저 불러와 처리하는 작업을 선행적으로 수행한다면 모든 메시지를 놓치지 않고 처리할 수 있다
    * XPENDING Email EmailServiceGroup
  * at most once vs. at least once vs. exactly once
    * at most once
      * 메시지를 최소 한 번 보낸다. 소비자는 메시지를 받자마자 ACK 먼저 보낸다. 속도는 향상되지만 처리하지 못한 데이터를 잃어버릴 수 있다
    * at least once 
      * 받은 메시지를 모두 처리한 뒤 ACK를 보낸다
      * 실제로 메시지는 처리됐지만 ACK 전송이 지연된 경우, 서비스가 재시작된다면 해당 지점의 메시지가 두 번 처리되게 된다. 멱등성이 보장되지 않는다면 위험하다
    * exactly once
      * set 자료 구조 등으로 이미 처리된 메시지인지 확인이 필요하다
## 레디스 데이터 백업
  * 레디스의 모든 데이터는 메모리에서 관리되어 레디스가 재시작될 경우 모든 데이터의 손실 가능성이 존재한다
  * 레디스를 캐시가 아닌 영구 저장소와 같은 용도로 사용한다면 디스크에 데이터를 주기적으로 백업하는 것이 안전하다
    * RDB(Redis Database)
      * 저장되는 시점의 메모리 데이터가 그대로 저장되는 스냅샷 방식이다
      * 최종적인 key의 값이 기록된다
      * 특정 조건(기간 내에 변경된 키의 개수 / 특정 시점)에 자동으로 RDB 파일 생성
      * 복제 생성 요청은 마스터 노드에서 RDB 파일을 새로 생성하여 복제본에 전달한다
    * AOF(Append Only File)
      * 레디스에서 실행된 모든 쓰기 작업이 기록된다
      * 생성/변경/삭제 내역이 모두 저장된다
      * 실수로 FLUSHALL 커맨드로 데이터를 모두 날려버렸다 해도 AOF 파일을 직접 열어 FLUSHALL 커맨드만 삭제한 뒤 레디스를 재시작하면 커맨드를 실행하기 직전까지 복구할 수 있다
    * 일반적인 Realtional DB 만큼의 안정성을 원한다면 두 가지 백업 방식을 동시에 사용한다
      * 이럴 거면 RDB 쓰는 게?
    * 레디스에서 데이터를 복원할 수 있는 시점은 서버자 재시작될 때뿐이며 레디스 인스턴스의 실행 도중에 데이터 파일을 읽어올 수 있는 방법은 없다
## 복제
* 복제 연결
  * Disk
    * 마스터 노드에서 fork로 자식 프로세스를 만든 뒤 RDB 스냅샷을 생성한다
    * 위 과정 동안 마스터 노드에서 수행된 변경 작업은 RESP 형태로 마스터의 복제 버퍼에 저장된다
    * 복제본에 저장된 모든 데이터를 모두 삭제한 뒤 RDB 파일 내용을 메모리에 로딩한다
    * 복제 버퍼의 데이터를 복제본으로 전달해 수행한다
  * Diskless
    * 마스터 노드는 소켓 통신을 이용해 복제본 노드에 연결하며 RDB 파일을 생성함과 동시에 점진적으로 복제본의 소켓에 전송한다
    * 이 과정 동안 마스터 노드에서 수행된 모든 데이터셋 변경 작업은 RESP(Redis Protocol) 형태로 마스터의 복제 버퍼에 저장된다
    * 소켓에서 읽어온 RDB 파일을 복제본의 디스크에 저장한다
    * 복제본에 저장된 모든 데이터를 모두 삭제한 뒤 RDB 파일 내용을 메모리에 로딩한다
    * 복제 버퍼의 데이터를 복제본으로 전달해 수행한다
  * Disk vs Diskless
    * 7.0부터는 diskless가 기본 옵션으로 설정된다
    * disk를 사용하는 방식에서의 복제 속도는 디스크 I/O 처리량에 영향을 받기 때문에 느리다
  * 정상적으로 복제 연결이 된 상태에서 마스터에서 복제본으로의 데이터 전달은 비동기 방식으로 동작한다
* 클러스터
  * 스케일 업 vs 스케일 아웃
    * Key Eviction(Max Memory만큼 데이터가 가득 차 있을 때 기존 데이터를 강제 삭제)이 자주 발생 > 스케일 업 고려
    * 처리량을 증가시키고자 할 때, 레디스는 단일 스레드로 동작하기 때문에 서버 CPU를 추가하더라도 CPU 코어를 동시에 활용할 수 없다 > 스케일 아웃을 고려
  * 데이터 샤딩
    * 데이터 저장소를 수평 확장하여 여러 서버 간에 데이터를 분할하는 데이터베이스 아키텍처 패턴을 샤딩이라고 한다
    * 모든 마스터 노드는 해시 슬롯을 나눠 가지며 입력되는 모든 키는 하나의 해시슬롯에 매핑된다
    * 클러스터를 사용할 때에는 다중 키 커맨드를 사용할 수 없다, 다른 해시슬롯에 속한 키를 가져올 수 없다 > 해시태그를 이용해 가져와야 한다