# 컴퓨터 밑바닥의 비밀

## 언어부터 실행까지
- 인간의 추상적인 표현을 CPU가 이해할 수 있는 구체적인 구현으로 변환할 수 있는 방법이 프로그래밍
- Statement: 프로그램이 수행할 동작을 명령하는 최소 단위의 독립적인 코드 구문
- Syntax: 프로그래밍 언어에서 문장을 올바르게 구성하기 위한 규칙의 집합
- Tree: 프로그램의 구조를 계층적으로 표현하는 자료구조로, 컴파일러가 코드를 분석하고 처리하는데 사용
- Compiler
  * 소스 코드에서 토큰을 추출(Lexical Analysis, 어휘분석)
  * 구문 트리 생성(Parsing, 구문 분석)
  * 이상 확인(Semantic analysis, 의미 분석)
- Linker
  * 컴파일러가 생성한 코드를 모듈 단위로 묶어 실행 파일 생성
  * 모듈 간 참조 관계 해결
  * 메모리 주소 할당
  * 대상 파일 > 실행 파일 생성
  * 동적 라이브러리는 프로그램이 메모리에 적재될 때 링크 과정 수행, Loader가 동적 라이브러리를 로드하고 링크
    * Spring Boot에서 많은 Spring Dependency를 추가해도 괜찮은 것이 동적 라이브러리를 사용하기 때문인가?
      * 지연 로딩(Lazy Loading)
        * 실제로 필요한 시점에만 라이브러리가 메모리에 로드됩니다
        * 사용하지 않는 의존성은 메모리를 차지하지 않습니다
      * 공유 라이브러리
        * JVM 위에서 실행되는 여러 애플리케이션이 같은 라이브러리를 공유할 수 있습니다
        * 메모리 사용량이 중복되지 않습니다
      * 자동 구성(Auto-configuration)
        * Spring Boot는 실제로 사용되는 기능만 구성합니다
        * 클래스패스에 있더라도 사용하지 않는 기능은 초기화되지 않습니다
  * 단점은 종속된 라이브러리를 제공하지 않거나 버전이 호환되지 않을 경우 까다로운 것

## 프로그램의 실행
- Program
  * 메모리에서 명령어(instruction)를 가져온다(dispatch)
  * PC(Program Counter) Register에 명령어 주소를 저장
  * 주소를 1씩 증가 또는 함수나 분기를 만나면 동적으로 실행 순서 변경
  * Context를 저장하면서 Process를 빠르게 전환하는 것으로 멀티태스킹을 구현
  * Operating System의 등장
  * OS는 코드 재사용성의 정수
  * IPC(Inter-Process Communication)는 OverHead, 프로세스마다 주소 공간이 달라 복잡한 구현
  * 힙, 스택, 데이터, 코드 영역 외의 메모리 여유 공간에는 동적 라이브러리의 코드와 데이터가 적재 
  * Thread
    * main 함수는 특별한가? 프로그램이 시작될 때 CPU가 실행하는 첫 번째 함수일 뿐이다. 
    * PC 레지스터가 다른 함수를 가리키게 할 수 있으면 새로운 실행 흐름을 형성할 수 있다 > 스레드
    * Thread-per-request 는 스레드의 생성과 종료에 많은 리소스 사용 > Thread-pool
    * producer-consumer pattern
    * Thread는 코드 영역에 read-only, 데이터 영역, 힙 영역에 write
    * 스레드 안전 문제의 핵심은 어떤 것이 스레드 전용 리소스이고, 어떤 것이 공유 리소스인지 구분하는 데 있다
      * 공유 리소스에의 접근은 각종 잠금이나 세마포어 같은 장치를 이용해야 한다
      * 무상태 함수, 불변 객체, 읽기 전용, 동기화 시 상호 배제 등으로 스레드 안전 코드를 구현할 수 있다
  * Coroutine
    * 자신의 이전 실행 상태를 기억하고 있다가 다시 실행될 때 이전에 일시 중지되었던 지점에서 계속 실행이 가능한 함수
    * 코틀린에서만 쓰는 게 아님
    * 마치 운영체제가 스레드를 스케줄링하는 것과 똑같음
    * 컴퓨터 시스템은 주기적으로 타이머 인터럽트(timer interrupt)를 생성하고 인터럽트가 처리될 때마다 현재 스레드의 일시 중지 여부를 결정할
    * 코루틴의 스택 영역은 힙 영역에 배치된다
  * CallBack
    * 함수를 파라미터로 받는 함수
    * event-driven-programming에 적합한 도구
  * 동기/비동기/블로킹/논블로킹
    * 동기 호출에서 주 스레드가 기다리는 시간이 Idle Time
    * 호출자의 스레드나 프로세스가 운영 체제에 의해 일시 중지되는 것이 블로킹/논블로킹의 핵심
    * 프로그래밍 관점에서 동기 호출은 반드시 블로킹이 아니지만, 블로킹 호출은 확실한 동기
  * 스레드는 커널 상태 스레드 / 코루틴은 사용자 상태 스레드
  * 코드를 할당, 사용, 매개변수로 전달, 반환값으로 사용할 수 있을 때 언어 함수를 일급 객체 함수라고 한다* 

## 저수준, 메모리
* 메모리 주소 > 포인터 > 참조 > 가상 메모리t
* 커널 상태와 사용자 상태
* CPU가 운영 체제의 코드를 실행할 때 > 커널 상태
* 모든 기계 명령어를 실행할 수 있고 모든 주소 공간에 접근할 수 있으며 하드웨어에 접근 가능
* 프로그래머가 작성한 일반적인 코드를 CPU가 실행라 때 > 사용자 상태
* 특정 주소 공간에 접근할 수 없음
* CPU는 커널 상태에서 응용 프로그램을 실행할 수 없고 사용자 상태에서는 운영 체제의 코드를 실행할 수 없음
* 시스템 호출(System Call)을 통해 전환
  * 프로그램은 malloc을 호출하여 메모리 할당 요청
  * malloc이 여유 메모리를 찾지 못하면 brk 시스템 호출을 통해 운영 체제에 힙 영역 확장 요청
  * 하지만 가상 메모리 시스템에서는 malloc으로 요청한 메모리는 사실 물리 메모리가 아님
  * 사용되는 순간에 물리 메모리를 할당(이 시점에 커널 상태)

## 트랜지스터에서 CPU로
* 트랜지스터 
  * 한쪽에 전류를 흘리면 나머지 단자 두 개에 전류가 흐르게 하거나 못 흐르게 하는 것
  * 논리곱, 논리합, 논리부정
  * 전문적으로 계산을 담당하는 모듈 ALU(Arithmetic Logic Unit)
  * 클럭 신호가 전압을 변경할 때마다 전체 회로의 각 레지스터(상태)가 갱신
  * 클럭 주파수가 높을수록 CPU가 더 많은 작업을 할 수 있음
  * ALU + 레지스터 + 클럭 신호 = CPU(또는 프로세서)
* CPU
  * 우리가 아무 것도 하지 않을 때 CPU는 무엇을 할까?
  * Windows의 System Idle Process는 스케쥴링 가능한 프로세스가 없을 때 이 유후 프로세스를 꺼내서 실행한다.
  * 무한 순환 탈출 > 인터럽트
    * OS는 일정 시간마다 타이머 인터럽트를 생성
    * 유후 프로세스가 타이머 인터럽트로 일시 중지되면 인터럽트 처리 함수는 시스템에 준비 완료된 프로세스를 확인하고 없으면 다시 유후 프로세스를 실행
  * 코어, 스레드
    * CPU 코어 수와 스레드 수 사이에는 필연 관계가 없다
    * CPU는 하드웨어인 반면 스레드는 소프트웨어 개념
    * CPU의 물리적 코어(Physical Core)는 실제 연산을 처리하는 하드웨어 유닛
    * CPU 스레드(Logical Core)는 하나의 물리적 코어가 동시에 처리할 수 있는 명령어 스트림의 수
    * 예: 4코어 8스레드 CPU는 4개의 물리적 코어가 각각 2개의 논리적 코어처럼 동작
    * 소프트웨어 스레드는 이와 별개로 운영체제가 관리하는 실행 흐름의 단위
    * Java 스레드 VS OS 스레드 VS CPU 스레드
      * CPU 스레드 (Hardware Thread / Logical Core)
        * 가장 하위 계층의 하드웨어 자원
        * 물리적 CPU 코어가 동시에 처리할 수 있는 명령어 스트림
        * 예: 4코어 8스레드 CPU는 8개의 논리적 프로세서 제공
      * OS 스레드 (Kernel Thread)
        * 운영체제가 CPU에 작업을 할당하는 기본 단위
        * 실제로 CPU 스레드 위에서 실행됨
        * 컨텍스트 스위칭을 통해 CPU 자원을 공유
        * 커널에 의해 직접 관리되며 스케줄링됨
      * Java 스레드 (User Thread)
        * Java 애플리케이션에서 생성하는 스레드
        * OS 스레드와 1:1로 매핑됨
        * 결국 하나의 Java 스레드는 하나의 OS 스레드를 사용
        * OS 스레드를 통해 최종적으로 CPU 스레드에서 실행
      * 실행 흐름 예시
        1. Java 애플리케이션에서 100개의 스레드 생성
        2. → 100개의 OS 스레드 생성 (1:1 매핑)
        3. → OS가 이 스레드들을 8개의 CPU 스레드에 스케줄링
        4. → 시분할 방식으로 번갈아가며 실행
      * 스케줄링 과정
        1. OS는 실행 가능한 스레드들을 런큐(Run Queue)에 관리
        2. 스케줄러는 가용한 CPU 스레드에 OS 스레드를 할당
        3. 각 OS 스레드는 할당된 시간(타임 슬라이스) 동안 CPU 스레드를 사용
        4. 시간이 만료되거나 I/O 작업 등으로 블록되면 다른 OS 스레드로 전환

      * 핵심 포인트
        * Java 스레드 : OS 스레드 = 1 : 1
        * OS 스레드 : CPU 스레드 = N : M (N ≥ M)
        * CPU 스레드는 실제 물리적 자원의 수 (예: 8개)
        * OS는 많은 수의 스레드를 적은 수의 CPU 스레드에 효율적으로 스케줄링
  * 하이퍼스레딩
    * 물리 CPU 코어가 하나지만 논리적으로 CPU 코어가 두 개 있는 것으로 인식
    * CPU 코어가 실제로 동시에 두 개를 실행
  
## 캐시
* 공짜 점심은 없다 > 캐시 갱신
  * 연속 기입(write-through) : 캐시를 갱신할 때 메모리도 함께 갱신
  * 후기입(write-back) : 캐시에서 제거된 데이터가 수정되면 메모리에 갱신
* 캐시 친화적인 프로그램
  * 이런 고민은 캐시 적중률이 시스템 성능의 병목이 되는지 판단이 우선
  * 프로그램 지역성의 원칙 > 프로그램이 매우 규칙적으로 메모리에 접근
  * 시간적 지역성과 공간적 지역성
  * 지역성 원칙 관점에서는 배열이 연결 리스트보다 낫다(캐시 관점)